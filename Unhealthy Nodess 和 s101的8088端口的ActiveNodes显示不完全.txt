1.现象




2.原因
当磁盘数少于一定量时，会把这台机器变成unhealthy，将不会再给这台机器分配任务。

yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage	90	The maximum percentage of disk space utilization allowed after which a disk is marked as bad. Values can range from 0.0 to 100.0. If the value is greater than or equal to 100, the nodemanager will check for full disk. This applies to yarn.nodemanager.local-dirs and yarn.nodemanager.log-dirs.
yarn.nodemanager.disk-health-checker.min-healthy-disks	0.25	The minimum fraction of number of disks to be healthy for the nodemanager to launch new containers. This correspond to both yarn.nodemanager.local-dirs and yarn.nodemanager.log-dirs. i.e. If there are less number of healthy local-dirs (or log-dirs) available, then new containers will not be launched on this node.
只要不足25%的磁盘少于90%磁盘使用量，就会不再分配container，防止中间结果和日志没有空间，该节点就Unhealthy了；

解决方法：
1.清理磁盘，比如我的磁盘原来剩下6G,总共120G,清理磁盘后，变成15G
2.解决方案-重启相关服务
2.1 重启nodemanager：

 /usr/local/goldmine/hadoop/default/sbin/yarn-daemon.sh stop nodemanager
 /usr/local/goldmine/hadoop/default/sbin/yarn-daemon.sh start nodemanager
1
2
2.2 重启resourcemanager，(否则会导致修改的节点状态错乱)

 /usr/local/goldmine/hadoop/default/sbin/yarn-daemon.sh stop resourcemanager
 /usr/local/goldmine/hadoop/default/sbin/yarn-daemon.sh start resourcemanager
1
2
2.3 刷新 http://localhost:8088/cluster/nodes 页面：
可以看到不健康的nodemanager已经消失在列表了。
2.4 命令显示yarn各节点状态：
lcc@lcc ~$     yarn node -list -all
18/10/17 22:08:30 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/10/17 22:08:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Total Nodes:1
         Node-Id	     Node-State	Node-Http-Address	Number-of-Running-Containers
 localhost:53758	        RUNNING	   localhost:8042	                           0
lcc@lcc ~$
